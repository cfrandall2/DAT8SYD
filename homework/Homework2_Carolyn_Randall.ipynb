{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 8 Homework 2 - Visualisation and Regression\n",
    "\n",
    "## Homework - Due Friday 30th June\n",
    "### Carolyn Randall\n",
    "\n",
    "#### Setup\n",
    "* Signup for an AWS account - **DONE**\n",
    "\n",
    "#### Communication\n",
    "* Imagine you are trying to explain to someone what Linear Regression is - but they have no programming/maths experience? How would you explain the overall process, what a p-value means and what R-Squared means?\n",
    "* Read the paper [Useful things to know about machine learning]( https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf). \n",
    "    * What have we covered so far from this paper? \n",
    "    * Explain sections 6-13 in your own words\n",
    "\n",
    "#### Machine Learning\n",
    "* Describe 3 ways we can select what features to use in a model\n",
    "* Complete the first 3 exercises from Chapter 3 of Introduction to Statistical Learning in Python\n",
    "\n",
    "#### Course Project\n",
    "* For the following setup a new github repository for your project and share it with Alasdair and Ian over Slack.\n",
    "* Load the data you have gathered for your project into Python and run some summary statistics over the data. Are there any interesting features of the data that jump out? (Include the code)\n",
    "* Draft/Sketch (or wireframe) some data visualisations that would be useful for you to explore your data set\n",
    "* Are there any regresion or clustering techniques you could use in your project? Write them down (with the corresponding scikit learn function) and what you think you would get out of it. Try it out if you get a chance.\n",
    "\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework2_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*******************************************************************************************\n",
    "*******************************************************************************************\n",
    "## **Communication - Carolyn Randall responses**\n",
    "## Communication - Linear Regression\n",
    "**Imagine you are trying to explain to someone what Linear Regression is - but they have no programming/maths experience? How would you explain the overall process, what a p-value means and what R-Squared means?**\n",
    "\n",
    "Linear regression is a common approach used in statistical modeling.  It is commonly used for prediction or forecasting or to find relationships in data.\n",
    "\n",
    "In simple linear regression, we predict scores on one variable from the scores on a second variable. The variable we are predicting is called the criterion variable and is referred to as Y. The variable we are basing our predictions on is called the predictor variable and is referred to as X. When there is only one predictor variable, the prediction method is called simple regression. In simple linear regression the predictions of Y when plotted as a function of X form a straight line.\n",
    "\n",
    "Linear regression consists of finding the best-fitting straight line through the points. The best-fitting line is called a regression line. \n",
    "\n",
    "\n",
    "For example, We may wish to look at the relationship between two things (e.g. between a person\"s height and weight) by comparing data for each of these things. A good way of doing this is by drawing a scatter diagram.\n",
    "\n",
    "\"Regression\" is the process of finding the function satisfied by the points on the scatter diagram. Of course, the points might not fit the function exactly but the aim is to get as close as possible. \"Linear\" means that the function we are looking for is a straight line (so our function f will be of the form f(x) = mx + c for constants m and c).\n",
    "\n",
    "\n",
    "\n",
    "### R squared below\n",
    "We now have a regression equation. But how good is the equation at predicting values of Y, for given values of X? For that assessment, we turn to measures of association and measures of statistical significance that are used with regression equations.\n",
    "\n",
    "r2 is a measure of association; it represents the percent of the variance in the values of Y that can be explained by knowing the value of X. r2 varies from a low of 0.0 (none of the variance is explained), to a high of +1.0 (all of the variance is explained).\n",
    "\n",
    "\n",
    "\n",
    "### p value used in muliple linear regression\n",
    "basically say you want to measure to see how valid your model is.  The p-value helps you determine the significance of your results.  You pick a cutoff value, which is typically 0.05.  \n",
    "\n",
    "If the p-value is less than 0.05, we reject the null hypothesis that there's no difference between the means and conclude that a significant difference does exist.\n",
    "\n",
    "A small p-value (typically ≤ 0.05) indicates strong evidence against the null hypothesis, so you reject the null hypothesis. A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject the null hypothesis.\n",
    "\n",
    "When you perform a hypothesis test in statistics, a p-value helps you determine the significance of your results. Hypothesis tests are used to test the validity of a claim that is made about a population. This claim that’s on trial, in essence, is called the null hypothesis.\n",
    "\n",
    "One main staple of research studies is called hypothesis testing. A hypothesis test is a technique for using data to validate or invalidate a claim about a population. For example, a politician may claim that 80% of the people in her state agree with her — is that really true? Or, a company may claim that they deliver pizzas in 30 minutes or less; is that really true? Medical researchers use hypothesis tests all the time to test whether or not a certain drug is effective, to compare a new drug to an existing drug in terms of its side effects, or to see which weight-loss program is more effective with a certain group of people.\n",
    "\n",
    "The elements about a population that are most often tested are\n",
    "\n",
    "## look below\n",
    "All hypothesis tests ultimately use a p-value to weigh the strength of the evidence (what the data are telling you about the population). The p-value is a number between 0 and 1 and interpreted in the following way:\n",
    "\n",
    "A small p-value (typically ≤ 0.05) indicates strong evidence against the null hypothesis, so you reject the null hypothesis.\n",
    "\n",
    "A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject the null hypothesis.\n",
    "\n",
    "p-values very close to the cutoff (0.05) are considered to be marginal (could go either way). Always report the p-value so your readers can draw their own conclusions.\n",
    "\n",
    "For example, suppose a pizza place claims their delivery times are 30 minutes or less on average but you think it’s more than that. You conduct a hypothesis test because you believe the null hypothesis, Ho, that the mean delivery time is 30 minutes max, is incorrect. Your alternative hypothesis (Ha) is that the mean time is greater than 30 minutes. You randomly sample some delivery times and run the data through the hypothesis test, and your p-value turns out to be 0.001, which is much less than 0.05. In real terms, there is a probability of 0.001 that you will mistakenly reject the pizza place’s claim that their delivery time is less than or equal to 30 minutes. Since typically we are willing to reject the null hypothesis when this probability is less than 0.05, you conclude that the pizza place is wrong; their delivery times are in fact more than 30 minutes on average, and you want to know what they’re gonna do about it! (Of course, you could be wrong by having sampled an unusually high number of late pizza deliveries just by chance.)\n",
    "\n",
    "\n",
    "A p-value is a probability associated with your critical value. The critical value depends on the probability you are allowing for a Type I error. It measures the chance of getting results at least as strong as yours if the claim (H0) were true.\n",
    "\n",
    "\n",
    "\n",
    "* Correlation\n",
    "\n",
    "*Correlation is a term used to describe how strong the relationship between the two variables *appears to be.\n",
    "\n",
    "*We say that there is a positive linear correlation if y increases as x increases and we say there is a negative linear correlation if y decreases as x increases. There is no correlation if x and y do not appear to be related.\n",
    "\n",
    "Explanatory and Response Variables\n",
    "\n",
    "In many experiments, one of the variables is fixed or controlled and the point of the experiment is to determine how the other variable varies with the first. The fixed/controlled variable is known as the explanatory or independent variable and the other variable is known as the response or dependent variable.\n",
    "\n",
    "We shall use \"x\" for the explanatory variable and \"y\" for the response variable, but we could have used any letters.\n",
    "\n",
    "*  Statistical researchers often use a linear relationship to predict the (average) numerical value of Y for a given value of X using a straight line (called the regression line). If you know the slope and the y-intercept of that regression line, then you can plug in a value for X and predict the average value for Y. In other words, you predict (the average) Y from X.\n",
    "\n",
    "* If you establish at least a moderate correlation between X and Y through both a correlation coefficient and a scatterplot, then you know they have some type of linear relationship.\n",
    "\n",
    "*  Statisticians call the X-variable (cricket chirps in this example) the explanatory variable, because if X changes, the slope tells you (or explains) how much Y is expected to change in response. Therefore, the Y variable is called the response variable. Other names for X and Y include the independent and dependent variables, respectively.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Communication - Machine Learning\n",
    "**Read the paper Useful things to know about machine learning.**\n",
    "* **What have we covered so far from this paper?**\n",
    "\n",
    "* **Explain sections 6-13 in your own words**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What have we covered so far from this paper\n",
    "* **Recommendation systems**\n",
    "* **Classification problems** - where the target variable is in a category and you try to classify what group it belongs to.\n",
    "* **Learning\\training data**  - used to test whether the classifer produces the correct output\n",
    "* **Algorithms available** - mentions there are a vast number of algorithms available to use and it is key to understand what they do so can can decide which ones you may want to use in your model\n",
    "*  **Representation** - some of the ways to represent the data that we covered and that are mentioned are:  k-nearest neighbor, Logistic regression, decision trees\n",
    "* **Evaluation** - for determining how your good your model is.  Using error measurements like squared error\n",
    "* **cross validation**  - randomly divide your training data into subsets, hold out one subset at a time and train the rest, then take an average to see how well a particular parameter does.\n",
    "* **over-fitting and variance** - Learner outs that are valid on the training data but not so accurate on the test data.  Variance for a given data point calculates the difference between the predicted and the actual value\n",
    "* ** underfitting and bias** - Bias measures how far off the predictions are from the actual values\n",
    "* **Regularization** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain sections 6-13 in your own words\n",
    "Sections 6-13 Some of the main points listed below.  \n",
    "* High dimenensions - After overfitting, dimesionality - which is refering to the number of features, is the 2nd biggest problem in machine learning.  The more features there are the harder generalizing becomes.  This makes it difficult to design a good classifier.\n",
    "* Theoretical Guarantees - I am not really sure I can put this in my own words.  But it talks about the most common type of theoretical quarantee being bound on the number of examples needed to make a good generalization.  There are things to be careful about regarding how the bund is obtained.  Another type is asympotic-given infinite data, the leaner is quaranteed to output the correct classifer.  In practive We are not often in a situation with infinite data.   The main role of theoretical gaurantee in ML is not as a criterian for for practical decisions but rather a source of understanding to help design the algorith.\n",
    "* Feature Engineering - Most important factor as to whether or not a ML project succeeds or fails is the features used.  A relatively small amount of time is actually spent doing machine learning.  More time is spent on gathering data, integrating it, clensing it and pre-processing it.  ML is not a one off run, but rather an iterative process of running the learner, analysing the results, modifying the data and/or learner and repeating.\n",
    "* More Data beats a cleverer Algorithm - In general, a less complex algorthm with lots and lots of data will perform better than a more complex algorithm with less data.  As a rule you should try simplier learners first.  The biggest bottlenecks are human effort rather than CPU or memory.  Learners that produce human-understandable output are favoured.\n",
    "* Learn many models - Discusses in the early days, people tried different learners and found the favourite and stuck mainly to using that.  Now it is best to try different learners, as the best learner may differ depending upon the application it is used on.  Combining learners is often the best outcome.\n",
    "* simplicity - This section says that if two classifiers give the same training error, it is not necessarily true that the simplier one will get the lower test error.\n",
    "* Representable does not imply learnable - Caution that just because a function can be represented does not mean it can be learned.\n",
    "* Correlation \\ Causation - Correlation does not imply causation.  ML is usually applied to observational data, where predicitive variables are not under the control of the learner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "* Describe 3 ways we can select what features to use in a model\n",
    "* Complete the first 3 exercises from Chapter 3 of Introduction to Statistical Learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 ways we can select what feature to use in a model\n",
    "*  Use Data Visualization - to get an overview of the data.  Plot the data.\n",
    "*  For a linear regression problem, you can look for linear correlations in the data using .corr() function.  then\n",
    "plot the data\n",
    "*   Run some OLS with different features and look at the OLS regression results - look at the R-squared values\n",
    "*   For non linear using Logistic Regression - split the data into training and testing, then fit a logistic regression model and examine the coefficients.  Run using different features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 from Chapter 3 - Intro to Statistical learning in Python\n",
    ". Describe the null hypotheses to which the p-values given in Table 3.4\n",
    "correspond. Explain what conclusions you can draw based on these\n",
    "p-values. Your explanation should be phrased in terms of sales, TV,\n",
    "radio, and newspaper, rather than in terms of the coefficients of the\n",
    "linear model.\n",
    "\n",
    "Table 3.4 displays the least squares coefficient estimates.  The intercept(B0) and the slope values define the population regression line.\n",
    "We test the null hypothesis which says there is not relationship between X (input variable - ad budgets) and Y (output variable - Sales in this case).  The null hypotheis would say the slope = 0 if no relationship.\n",
    "\n",
    "We would reject the null hypothesis—that is, we declare a relationship to exist between X and Y —if the p-value is small enough. \n",
    "The p-value tests the null hypothesis.  coefficent = 0 has no effect.  So a low p-value usually < 0.05 you would reject the null hypothesis.\n",
    "Looking at table 3.4 we can see the advertising budgets for TV and Radio p-values are low therefore they are significant for TV and radio.  For newspaper however, we can conclude that newspaper budget does not affect sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    " Carefully explain the differences between the KNN classifier and KNN\n",
    "regression methods.\n",
    "#### KNN Classifier\n",
    "The KNN (K nearest neighbors) classifier is typically used to solve classification problems, which are problems with a qualitative response.  The algorithm determines what class a data point should belong to.  You select a K value and you then find the K closest points that have similiar attributes  \n",
    "\n",
    "\n",
    "#### KNN Regression method\n",
    "The KNN regression method is used to solve regression problems, which are those with a qualitative response.\n",
    "KNN regression is one of the simpliest and best-known non-parametric method.  You pick a value for K and for each prediction point first determines the K observations that are nearest the prediction.  It then estimates using an average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    " Suppose we have a data set with five predictors, X1 = GPA, X2 = IQ,\n",
    "X3 = Gender (1 for Female and 0 for Male), X4 = Interaction between\n",
    "GPA and IQ, and X5 = Interaction between GPA and Gender. The\n",
    "response is starting salary after graduation (in thousands of dollars).\n",
    "Suppose we use least squares to fit the model, and get βˆ0 = \n",
    "50, βˆ1 = 20, βˆ2 = 0.07, βˆ3 = 35, βˆ4 = 0.01, βˆ5 = −10.\n",
    "\n",
    "(a) Which answer is correct, and why?\n",
    "i. For a fixed value of IQ and GPA, males earn more on average\n",
    "than females.\n",
    "\n",
    "ii. For a fixed value of IQ and GPA, females earn more on\n",
    "average than males.\n",
    "\n",
    "iii. For a fixed value of IQ and GPA, males earn more on average\n",
    "than females provided that the GPA is high enough.\n",
    "\n",
    "iv. For a fixed value of IQ and GPA, females earn more on\n",
    "average than males provided that the GPA is high enough.\n",
    "\n",
    "**Answer is iii.** \n",
    "\n",
    "The least square line is given by\n",
    "ŷ =50+20GPA+0.07IQ+35Gender+0.01GPA×IQ−10GPA×Gender\n",
    "\n",
    "y^=50+20GPA+0.07IQ+35Gender+0.01GPA×IQ−10GPA×Gender\n",
    "\n",
    "which becomes for the males\n",
    "\n",
    "ŷ =50+20GPA+0.07IQ+0.01GPA×IQ,\n",
    "\n",
    "y^=50+20GPA+0.07IQ+0.01GPA×IQ,\n",
    "\n",
    "and for the females\n",
    "\n",
    "ŷ =85+10GPA+0.07IQ+0.01GPA×IQ.\n",
    "\n",
    "y^=85+10GPA+0.07IQ+0.01GPA×IQ.\n",
    "\n",
    "So the starting salary for males is higher than for females on average iff 50+20GPA≥85+10GPA50+20GPA≥85+10GPA which is equivalent to GPA≥3.5GPA≥3.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Predict the salary of a female with IQ of 110 and a GPA of 4.0.\n",
    "\n",
    "plug in the given values in the least square line for females given above and we obtain\n",
    "\n",
    "ŷ =85+40+7.7+4.4=137.1,\n",
    "\n",
    "y^=85+40+7.7+4.4=137.1,\n",
    "\n",
    "which gives us a starting salary of 137100$137100$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) True or false: Since the coefficient for the GPA/IQ interaction\n",
    "term is very small, there is very little evidence of an interaction\n",
    "effect. Justify your answer.\n",
    "\n",
    "False. To verify if the GPA/IQ has an impact on the quality of the model we need to test the hypothesis H0:β4^=0H0:β4^=0 and look at the p-value associated with the tt or the FF statistic to draw a conclusion.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
